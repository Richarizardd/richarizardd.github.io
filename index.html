<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Richard J. Chen</title>
<meta name="description" content="">

<!-- Open Graph -->

<meta property="og:site_name" content="" />
<meta property="og:type" content="object" />
<meta property="og:title" content="" />
<meta property="og:url" content="/" />
<meta property="og:description" content="about" />
<meta property="og:image" content="" />


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- Theming-->

  <script src="/assets/js/theme.js"></script>



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-XXXXXXXXX');
  </script>


    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="navbar-brand social">
          <a href="mailto:%72%69%63%68%61%72%64%63%68%65%6E@%67.%68%61%72%76%61%72%64.%65%64%75"><i class="fas fa-envelope"></i></a>
<a href="https://orcid.org/0000-0003-0389-1331" target="_blank" title="ORCID"><i class="ai ai-orcid"></i></a>
<a href="https://scholar.google.com/citations?user=yhGqdMgAAAAJ&hl" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/richarizardd" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/richardchen95" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/richardjchen" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>










        </div>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>

    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Richard</span> J.  Chen
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-left">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <p>I am a 3rd year Ph.D. Candidate (and NSF-GRFP Fellow) advised by <a href="https://faisal.ai">Faisal Mahmood</a> at <a href="https://bigphd.hms.harvard.edu/">Harvard University</a>, and also within Brigham and Women’s Hospital, Dana-Farber Cancer Institute, and the Broad Institute.</p>

<p>Prior to starting my Ph.D., I obtained my B.S/M.S. in Biomedical Engineering and Computer Science at Johns Hopkins University, where I worked with <a href="https://durr.jhu.edu">Nicholas Durr</a> and <a href="https://ccvl.jhu.edu/">Alan Yuille</a>. In industry, I have also worked at Apple Inc. in the Health Special Project and Applied Machine Learning Groups (with <a href="https://scholar.google.com/citations?user=3CS_ahUAAAAJ&amp;hl=en">Belle Tseng</a> and <a href="https://www.gatesfoundation.org/about/leadership/andrew-trister">Andrew Trister</a>), and at Microsoft Research in the BioML Group (with <a href="http://www.cs.toronto.edu/~rahulgk/index.html">Rahul Gopalkrishnan</a>).</p>

<h3 id="research-highlights">Research Highlights</h3>

<ul>
  <li>
    <p><strong>Multimodal Integration</strong>: Multimodal learning has emerged as an interdisciplinary field to solve many core problems in machine perception, human-computer interaction, and recently in biology &amp; medicine, in which there is often an enormous wealth of multimodal data collected in parallel to study the same underlying disease. Since first starting out in research, I have a range of experiences working on multimodal learning for integrating: 1) <a href="https://machinelearning.apple.com/research/developing-measures-of-cognitive-impairment-in-the-real-world-from-consumer-grade-multimodal-sensor-streams">multimodal sensor streams from the Apple Watch and iPhone Data</a> to predict mild cognitive decline, 2) <a href="https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy">RGB and depth images</a> for non-polyploidal lesion classification and SLAM in surgical robotics,  and 3) <a href="https://arxiv.org/abs/2108.02278">pathology images and genomics</a> for cancer prognosis.</p>
  </li>
  <li>
    <p><strong>Weakly-Supervised &amp; Set-Based Deep Learning</strong>: Though deep learning has revolutionized computer vision in many disciplines, gigapixel whole-slide imaging (WSI) in computational pathology is a complex computer vision domain that renders traditional, Convnet-based supervised learning approaches infeasible. To address this issue, I have been working on <a href="https://www.nature.com/articles/s41551-020-00682-w">interpretting large gigapixel images as permutation-invariant sets</a> (or bags in MIL literature), and then developing set-based learning algorithms for weakly-supervised learning on WSIs.</p>
  </li>
  <li>
    <p><strong>Synthetic Data Generation &amp; Domain Adaption</strong>: “What constitutes authenticity, and how would the lack of authenticity shape our perception of reality?” The science fiction American writer Philip K. Dick posited similar questions throughout his literary career and, in particular, in his 1972 essay “How to build a universe that doesn’t fall apart two days later”. I am interested in: <a href="https://arxiv.org/abs/1711.06606">using synthetic data for domain adaptation / generalization</a>, <a href="https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy"> developing synthetic environments for simulating challenging scenarios for neural networks</a>, as well as the the <a href="https://www.nature.com/articles/s41551-021-00751-8">policy challenges in training AI-SaMDs with synthetic data</a>,</p>
  </li>
</ul>

<p><strong>Prospective Summer Interns, Undergraduate / Master Students, and other Visiting Students:</strong> Several positions in the Mahmood Lab are open for projects around weakly-supervised, self-supervised, and multimodal learning for CPATH. Email <a href="mailto:richardchen@.g.harvard.edu">richardchen@g.harvard.edu</a> with your resume / CV, and a brief research statement on what you’re interested in!</p>


    </div>

    
      <div class="news">
  <h2>Recent News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Feb, 2022</th>
          <td>
            
              In press, <a href="https://www.sciencedirect.com/science/article/pii/S1361841521003431">federated learning for CPATH (HistoFL)</a> was published in Medical Image Analysis. Lastly, my summer intern, Yicong Li, was accepted into the Computer Science Ph.D. program at Harvard University (SEAS). Congratulations Yicong!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Nov, 2021</th>
          <td>
            
              In press, my editorial on <a href="https://www.nature.com/articles/s41746-021-00534-0">human-augmented labeling systems (HALS) for CPATH</a> was published in npj Digital Medicine. Excited to also announce that my preprint on <a href="https://arxiv.org/abs/2110.00603">algorithm fairness for medicine and healthcare</a> is on arXiv! Please reach out if you have any feedback on this work :)

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Aug, 2021</th>
          <td>
            
              Excited to announce that the preprint for <a href="https://arxiv.org/abs/2108.02278">PORPOISE</a>, our <strong>P</strong>athology-<strong>O</strong>mic <strong>R</strong>esearch <strong>P</strong>latform f<strong>o</strong>r <strong>I</strong>ntegrated <strong>S</strong>urvival <strong>E</strong>stimation, is out (with its associated <a href="http://pancancer.mahmoodlab.org">demo</a>)!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul, 2021</th>
          <td>
            
              Two papers, <a href="https://arxiv.org/abs/2107.13048">Patch-GCN</a> and Multimodal Co-Attention Transformers (<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Multimodal_Co-Attention_Transformer_for_Survival_Prediction_in_Gigapixel_Whole_Slide_ICCV_2021_paper.html">MCAT</a>), were accepted into MICCAI and ICCV respectively.


            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun, 2021</th>
          <td>
            
              Joined Microsoft Research as an PhD Research Intern, working with Rahul Gopalkrishnan in the BioML Group. In press, commentary on <a href="https://www.nature.com/articles/s41551-021-00751-8">synthetic data for machine learning and healthcare</a> was also published in Nature Biomedical Engineering. Lastly, I passed my Qualifying Exam, and am now a PhD Candidate!

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Select Publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-3">
  
    <img class="img-fluid" src="/assets/pubimg/chen2019developing.png">
  
  </div>

  <div id="chen2019developing" class="col-sm-8">
    
      <div class="title">Developing Measures of Cognitive Impairment in the Real World from Consumer-Grade Multimodal Sensor Streams</div>
      <div class="author">
        
          

          

          

          
            
              
                <em>Richard J. Chen*</em>,
              
            
          
        
          

          

          

          
            
              
                
                  Filip Jankovic*,
                
              
            
          
        
          

          

          

          
            
              
                
                  Nikki Marinsek*,
                
              
            
          
        
          

          

          

          
            
              
                
                  Luca Foschini,
                
              
            
          
        
          

          

          

          
            
              
                
                  Lampros Kourtis,
                
              
            
          
        
          

          

          

          
            
              
                
                  Alessio Signorini,
                
              
            
          
        
          

          

          

          
            
              
                
                  Melissa Pugh,
                
              
            
          
        
          

          

          

          
            
              
                
                  Jie Shen,
                
              
            
          
        
          

          

          

          
            
              
                
                  Roy Yaari,
                
              
            
          
        
          

          

          

          
            
              
                
                  Vera Maljkovic,
                
              
            
          
        
          

          

          

          
            
              
                
                  Marc Sunga,
                
              
            
          
        
          

          

          

          
            
              
                
                  Han Hee Song,
                
              
            
          
        
          

          

          

          
            
              
                
                  Hyun Joon Jung,
                
              
            
          
        
          

          

          

          
            
              
                
                  Belle Tseng,
                
              
            
          
        
          

          

          

          
            
              
                
                  and Andrew Trister
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining</em>
      
      
        2019
      
      
      </div>

      <div class="honor">
        
          Oral Presentation & Best Paper Runner-Up
        
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://machinelearning.apple.com/research/developing-measures-of-cognitive-impairment-in-the-real-world-from-consumer-grade-multimodal-sensor-streams" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      <a href="https://www.youtube.com/watch?v=H_wTI4LUW7A" class="btn btn-sm z-depth-0" role="button" target="_blank">Oral</a>
    
    
      <a href="https://www.technologyreview.com/2019/08/08/102821/your-apple-watch-might-one-day-spot-if-youre-developing-alzheimers/" class="btn btn-sm z-depth-0" role="button" target="_blank">News</a>
    
    
    
    
    
    
    
    
    
    
      <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The ubiquity and remarkable technological progress of wearable consumer devices and mobile-computing platforms (smart phone, smart watch, tablet), along with the multitude of sensor modalities available, have enabled continuous monitoring of patients and their daily activities. Such rich, longitudinal information can be mined for physiological and behavioral signatures of cognitive impairment and provide new avenues for detecting MCI in a timely and cost-effective manner. In this work, we present a platform for remote and unobtrusive monitoring of symptoms related to cognitive impairment using several consumer-grade smart devices. We demonstrate how the platform has been used to collect a total of 16TB of data during the Lilly Exploratory Digital Assessment Study, a 12-week feasibility study which monitored 31 people with cognitive impairment and 82 without cognitive impairment in free living conditions. We describe how careful data unification, time-alignment, and imputation techniques can handle missing data rates inherent in real-world settings and ultimately show utility of these disparate data in differentiating symptomatics from healthy controls based on features computed purely from device data.</p>
    </div>
    
    
    <div class="bibtex hidden">
      <pre>@inproceedings{chen2019developing,
  doi = {10.1145/3292500.3330690},
  url = {https://machinelearning.apple.com/research/developing-measures-of-cognitive-impairment-in-the-real-world-from-consumer-grade-multimodal-sensor-streams},
  year = {2019},
  month = jul,
  publisher = {{ACM}},
  author = {Chen*, Richard J. and Jankovic*, Filip and Marinsek*, Nikki and Foschini, Luca and Kourtis, Lampros and Signorini, Alessio and Pugh, Melissa and Shen, Jie and Yaari, Roy and Maljkovic, Vera and Sunga, Marc and Song, Han Hee and Jung, Hyun Joon and Tseng, Belle and Trister, Andrew},
  title = {Developing Measures of Cognitive Impairment in the Real World from Consumer-Grade Multimodal Sensor Streams},
  booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on Knowledge Discovery {\&} Data Mining},
  honor = {Oral Presentation & Best Paper Runner-Up},
  press = {https://www.technologyreview.com/2019/08/08/102821/your-apple-watch-might-one-day-spot-if-youre-developing-alzheimers/},
  abbr = {chen2019developing.png},
  oral = {https://www.youtube.com/watch?v=H_wTI4LUW7A},
  selected = {true}
}
</pre>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3">
  
    <img class="img-fluid" src="/assets/pubimg/chen2021pan.png">
  
  </div>

  <div id="chen2021pan" class="col-sm-8">
    
      <div class="title">Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning</div>
      <div class="author">
        
          

          

          

          
            
              
                <em>Richard J Chen</em>,
              
            
          
        
          

          

          

          
            
              
                
                  Ming Y Lu,
                
              
            
          
        
          

          

          

          
            
              
                
                  Drew FK Williamson,
                
              
            
          
        
          

          

          

          
            
              
                
                  Tiffany Y Chen,
                
              
            
          
        
          

          

          

          
            
              
                
                  Jana Lipkova,
                
              
            
          
        
          

          

          

          
            
              
                
                  Muhammad Shaban,
                
              
            
          
        
          

          

          

          
            
              
                
                  Maha Shady,
                
              
            
          
        
          

          

          

          
            
              
                
                  Mane Williams,
                
              
            
          
        
          

          

          

          
            
              
                
                  Bumjin Joo,
                
              
            
          
        
          

          

          

          
            
              
                
                  Zahra Noor,
                
              
            
          
        
          

          

          

          
            
              
                
                  and Faisal Mahmood
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2108.02278</em>
      
      
        2021
      
      
      </div>

      <div class="honor">
        
          Best Paper, Case Western Artificial Intelligence in Oncology Symposium, 2020.
        
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2108.02278" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
      <a href="https://github.com/mahmoodlab/PORPOISE" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
      <a href="http://pancancer.mahmoodlab.org" class="btn btn-sm z-depth-0" role="button" target="_blank">Demo</a>
    
    
      <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The rapidly emerging field of deep learning-based computational pathology has demonstrated promise in developing objective prognostic models from histology whole slide images. However, most prognostic models are either based on histology or genomics alone and do not address how histology and genomics can be integrated to develop joint image-omic prognostic models. Additionally identifying explainable morphological and molecular descriptors from these models that govern such prognosis is of interest. We used multimodal deep learning to integrate gigapixel whole slide pathology images, RNA-seq abundance, copy number variation, and mutation data from 5,720 patients across 14 major cancer types. Our interpretable, weakly-supervised, multimodal deep learning algorithm is able to fuse these heterogeneous modalities for predicting outcomes and discover prognostic features from these modalities that corroborate with poor and favorable outcomes via multimodal interpretability. We compared our model with unimodal deep learning models trained on histology slides and molecular profiles alone, and demonstrate performance increase in risk stratification on 9 out of 14 cancers. In addition, we analyze morphologic and molecular markers responsible for prognostic predictions across all cancer types. All analyzed data, including morphological and molecular correlates of patient prognosis across the 14 cancer types at a disease and patient level are presented in an interactive open-access database (http://pancancer.mahmoodlab.org) to allow for further exploration and prognostic biomarker discovery. To validate that these model explanations are prognostic, we further analyzed high attention morphological regions in WSIs, which indicates that tumor-infiltrating lymphocyte presence corroborates with favorable cancer prognosis on 9 out of 14 cancer types studied.</p>
    </div>
    
    
    <div class="bibtex hidden">
      <pre>@article{chen2021pan,
  title = {Pan-Cancer Integrative Histology-Genomic Analysis via Interpretable Multimodal Deep Learning},
  author = {Chen, Richard J and Lu, Ming Y and Williamson, Drew FK and Chen, Tiffany Y and Lipkova, Jana and Shaban, Muhammad and Shady, Maha and Williams, Mane and Joo, Bumjin and Noor, Zahra and Mahmood, Faisal},
  journal = {arXiv preprint arXiv:2108.02278},
  year = {2021},
  arxiv = {2108.02278},
  code = {https://github.com/mahmoodlab/PORPOISE},
  demo = {http://pancancer.mahmoodlab.org},
  selected = {true},
  abbr = {chen2021pan.png},
  honor = {Best Paper, Case Western Artificial Intelligence in Oncology Symposium, 2020.}
}
</pre>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3">
  
    <img class="img-fluid" src="/assets/pubimg/chen2021multimodal.png">
  
  </div>

  <div id="chen2021multimodal" class="col-sm-8">
    
      <div class="title">Multimodal Co-Attention Transformer for Survival Prediction in Gigapixel Whole Slide Images</div>
      <div class="author">
        
          

          

          

          
            
              
                <em>Richard J. Chen</em>,
              
            
          
        
          

          

          

          
            
              
                
                  Ming Y. Lu,
                
              
            
          
        
          

          

          

          
            
              
                
                  Wei H. Weng,
                
              
            
          
        
          

          

          

          
            
              
                
                   Tiffany Y Chen,
                
              
            
          
        
          

          

          

          
            
              
                
                  Drew FK Williamson,
                
              
            
          
        
          

          

          

          
            
              
                
                  Trevor Manz,
                
              
            
          
        
          

          

          

          
            
              
                
                  Maha Shady,
                
              
            
          
        
          

          

          

          
            
              
                
                  and Faisal Mahmood
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>
      
      
        2021
      
      
      </div>

      <div class="honor">
        
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Multimodal_Co-Attention_Transformer_for_Survival_Prediction_in_Gigapixel_Whole_Slide_ICCV_2021_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
      <a href="https://github.com/mahmoodlab/MCAT" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    
      <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Survival outcome prediction is a challenging weakly-supervised and ordinal regression task in computational pathology that involves modeling complex interactions within the tumor microenvironment in gigapixel whole slide images (WSIs). Despite recent progress in formulating WSIs as bags for multiple instance learning (MIL), representation learning of entire WSIs remains an open and challenging problem, especially in overcoming: 1) the computational complexity of feature aggregation in large bags, and 2) the data heterogeneity gap in incorporating biological priors such as genomic measurements. In this work, we present a Multimodal Co-Attention Transformer (MCAT) framework that learns an interpretable, dense co-attention mapping between WSIs and genomic features formulated in an embedding space. Inspired by approaches in Visual Question Answering (VQA) that can attribute how word embeddings attend to salient objects in an image when answering a question, MCAT learns how histology patches attend to genes when predicting patient survival. In addition to visualizing multimodal interactions, our co-attention transformation also reduces the space complexity of WSI bags, which enables the adaptation of Transformer layers as a general encoder backbone in MIL. We apply our proposed method on five different cancer datasets (4,730 WSIs, 67 million patches). Our experimental results demonstrate that the proposed method consistently achieves superior performance compared to the state-of-the-art methods.</p>
    </div>
    
    
    <div class="bibtex hidden">
      <pre>@inproceedings{chen2021multimodal,
  title = {Multimodal Co-Attention Transformer for Survival Prediction in Gigapixel Whole Slide Images},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Multimodal_Co-Attention_Transformer_for_Survival_Prediction_in_Gigapixel_Whole_Slide_ICCV_2021_paper.html},
  author = {Chen, Richard J. and Lu, Ming Y. and Weng, Wei H. and and Tiffany Y Chen and Williamson, Drew FK and Manz, Trevor and Shady, Maha and Mahmood, Faisal},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages = {4015--4025},
  year = {2021},
  code = {https://github.com/mahmoodlab/MCAT},
  abbr = {chen2021multimodal.png},
  selected = {true}
}
</pre>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3">
  
    <img class="img-fluid" src="/assets/pubimg/chen2021algorithm.png">
  
  </div>

  <div id="chen2021algorithm" class="col-sm-8">
    
      <div class="title">Algorithm Fairness in AI for Medicine and Healthcare</div>
      <div class="author">
        
          

          

          

          
            
              
                <em>Richard J. Chen</em>,
              
            
          
        
          

          

          

          
            
              
                
                  Tiffany Y. Chen,
                
              
            
          
        
          

          

          

          
            
              
                
                  Jana Lipkova,
                
              
            
          
        
          

          

          

          
            
              
                
                  Judy J. Wang,
                
              
            
          
        
          

          

          

          
            
              
                
                  Drew FK. Williamson,
                
              
            
          
        
          

          

          

          
            
              
                
                  Ming Y. Lu,
                
              
            
          
        
          

          

          

          
            
              
                
                  Sharifa Sahai,
                
              
            
          
        
          

          

          

          
            
              
                
                  and Faisal Mahmood
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2110.00603</em>
      
      
        2021
      
      
      </div>

      <div class="honor">
        
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2110.00603" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    
    
    
      <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In the current development and deployment of many artificial intelligence (AI) systems in healthcare, algorithm fairness is a challenging problem in delivering equitable care. Recent evaluation of AI models stratified across race sub-populations have revealed enormous inequalities in how patients are diagnosed, given treatments, and billed for healthcare costs. In this perspective article, we summarize the intersectional field of fairness in machine learning through the context of current issues in healthcare, outline how algorithmic biases (e.g. - image acquisition, genetic variation, intra-observer labeling variability) arise in current clinical workflows and their resulting healthcare disparities. Lastly, we also review emerging strategies for mitigating bias via decentralized learning, disentanglement, and model explainability.</p>
    </div>
    
    
    <div class="bibtex hidden">
      <pre>@article{chen2021algorithm,
  title = {Algorithm Fairness in AI for Medicine and Healthcare},
  author = {Chen, Richard J. and Chen, Tiffany Y. and Lipkova, Jana and Wang, Judy J. and Williamson, Drew FK. and Lu, Ming Y. and Sahai, Sharifa and Mahmood, Faisal},
  journal = {arXiv preprint arXiv:2110.00603},
  year = {2021},
  selected = {true},
  abbr = {chen2021algorithm.png},
  arxiv = {2110.00603}
}
</pre>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3">
  
    <img class="img-fluid" src="/assets/pubimg/chen2021synthetic.png">
  
  </div>

  <div id="chen2021synthetic" class="col-sm-8">
    
      <div class="title">Synthetic Data in Machine Learning for Medicine and Healthcare</div>
      <div class="author">
        
          

          

          

          
            
              
                <em>Richard J. Chen</em>,
              
            
          
        
          

          

          

          
            
              
                
                  Ming Y. Lu,
                
              
            
          
        
          

          

          

          
            
              
                
                  Tiffany Y. Chen,
                
              
            
          
        
          

          

          

          
            
              
                
                  Drew F. K. Williamson,
                
              
            
          
        
          

          

          

          
            
              
                
                  and Faisal Mahmood
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Nature Biomedical Engineering</em>
      
      
        2021
      
      
      </div>

      <div class="honor">
        
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1038/s41551-021-00751-8" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    
    
    
    
      <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The proliferation of synthetic data in artificial intelligence for medicine and healthcare raises concerns about the vulnerabilities of the software and the challenges of current policy.</p>
    </div>
    
    
    <div class="bibtex hidden">
      <pre>@article{chen2021synthetic,
  doi = {10.1038/s41551-021-00751-8},
  url = {https://doi.org/10.1038/s41551-021-00751-8},
  year = {2021},
  month = jun,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {5},
  number = {6},
  pages = {493--497},
  author = {Chen, Richard J. and Lu, Ming Y. and Chen, Tiffany Y. and Williamson, Drew F. K. and Mahmood, Faisal},
  title = {Synthetic Data in Machine Learning for Medicine and Healthcare},
  journal = {Nature Biomedical Engineering},
  abbr = {chen2021synthetic.png},
  selected = {true}
}
</pre>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3">
  
    <img class="img-fluid" src="/assets/pubimg/lu2022histofl.png">
  
  </div>

  <div id="lu2022federated" class="col-sm-8">
    
      <div class="title">Federated Learning for Computational Pathology on Gigapixel Whole Slide Images</div>
      <div class="author">
        
          

          

          

          
            
              
                
                  Ming Y. Lu*,
                
              
            
          
        
          

          

          

          
            
              
                <em>Richard J. Chen*</em>,
              
            
          
        
          

          

          

          
            
              
                
                  Dehan Kong,
                
              
            
          
        
          

          

          

          
            
              
                
                  Jana Lipkova,
                
              
            
          
        
          

          

          

          
            
              
                
                  Rajendra Singh,
                
              
            
          
        
          

          

          

          
            
              
                
                  Drew FK. Williamson,
                
              
            
          
        
          

          

          

          
            
              
                
                  Tiffany Y. Chen,
                
              
            
          
        
          

          

          

          
            
              
                
                  and Faisal Mahmood
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Medical Image Analysis</em>
      
      
        2022
      
      
      </div>

      <div class="honor">
        
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2009.10190" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      <a href="https://www.sciencedirect.com/science/article/pii/S1361841521003431" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
      <a href="https://github.com/mahmoodlab/HistoFL" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    
      <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep Learning-based computational pathology algorithms have demonstrated profound ability to excel in a wide array of tasks that range from characterization of well known morphological phenotypes to predicting non-human-identifiable features from histology such as molecular alterations. However, the development of robust, adaptable, and accurate deep learning-based models often rely on the collection and time-costly curation large high-quality annotated training data that should ideally come from diverse sources and patient populations to cater for the heterogeneity that exists in such datasets. Multi-centric and collaborative integration of medical data across multiple institutions can naturally help overcome this challenge and boost the model performance but is limited by privacy concerns amongst other difficulties that may arise in the complex data sharing process as models scale towards using hundreds of thousands of gigapixel whole slide images. In this paper, we introduce privacy-preserving federated learning for gigapixel whole slide images in computational pathology using weakly-supervised attention multiple instance learning and differential privacy. We evaluated our approach on two different diagnostic problems using thousands of histology whole slide images with only slide-level labels. Additionally, we present a weakly-supervised learning framework for survival prediction and patient stratification from whole slide images and demonstrate its effectiveness in a federated setting. Our results show that using federated learning, we can effectively develop accurate weakly supervised deep learning models from distributed data silos without direct data sharing and its associated complexities, while also preserving differential privacy using randomized noise generation.</p>
    </div>
    
    
    <div class="bibtex hidden">
      <pre>@article{lu2022federated,
  title = {Federated learning for computational pathology on gigapixel whole slide images},
  url = {https://www.sciencedirect.com/science/article/pii/S1361841521003431},
  author = {Lu*, Ming Y. and Chen*, Richard J. and Kong, Dehan and Lipkova, Jana and Singh, Rajendra and Williamson, Drew FK. and Chen, Tiffany Y. and Mahmood, Faisal},
  journal = {Medical Image Analysis},
  volume = {76},
  pages = {102298},
  year = {2022},
  publisher = {Elsevier},
  code = {https://github.com/mahmoodlab/HistoFL},
  abbr = {lu2022histofl.png},
  selected = {true},
  arxiv = {2009.10190}
}
</pre>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3">
  
    <img class="img-fluid" src="/assets/pubimg/chen2019pathomic.png">
  
  </div>

  <div id="chen2019pathomic" class="col-sm-8">
    
      <div class="title">Pathomic Fusion: An Integrated Framework for Fusing Histopathology and Genomic Features for Cancer Diagnosis and Prognosis</div>
      <div class="author">
        
          

          

          

          
            
              
                <em>Richard J. Chen</em>,
              
            
          
        
          

          

          

          
            
              
                
                  Ming Y. Lu,
                
              
            
          
        
          

          

          

          
            
              
                
                  Jingwen Wang,
                
              
            
          
        
          

          

          

          
            
              
                
                  Drew F. K. Williamson,
                
              
            
          
        
          

          

          

          
            
              
                
                  Scott J. Rodig,
                
              
            
          
        
          

          

          

          
            
              
                
                  Neal I. Lindeman,
                
              
            
          
        
          

          

          

          
            
              
                
                  and Faisal Mahmood
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Medical Imaging</em>
      
      
        2020
      
      
      </div>

      <div class="honor">
        
          Top 5 Posters, NVIDIA GTC 2020
        
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1912.08937" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      <a href="https://www.youtube.com/watch?v=TrjGEUVX5YE" class="btn btn-sm z-depth-0" role="button" target="_blank">Oral</a>
    
    
      <a href="https://blogs.nvidia.com/blog/2019/11/07/harvard-pathology-lab-data-fusion-ai-cancer/" class="btn btn-sm z-depth-0" role="button" target="_blank">News</a>
    
    
    
    
    
      <a href="https://github.com/mahmoodlab/PathomicFusion" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    
      <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Cancer diagnosis, prognosis, and therapeutic response predictions are based on morphological information from histology slides and molecular profiles from genomic data. However, most deep learning-based objective outcome prediction and grading paradigms are based on histology or genomics alone and do not make use of the complementary information in an intuitive manner. In this work, we propose Pathomic Fusion, an interpretable strategy for end-to-end multimodal fusion of histology image and genomic (mutations, CNV, RNASeq) features for survival outcome prediction. Our approach models pairwise feature interactions across modalities by taking the Kronecker product of unimodal feature representations, and controls the expressiveness of each representation via a gatingbased attention mechanism. Following supervised learning, we are able to interpret and saliently localize features across each modality, and understand how feature importance shifts when conditioning on multimodal input. We validate our approach using glioma and clear cell renal cell carcinoma datasets from the Cancer Genome Atlas (TCGA), which contains paired wholeslide image, genotype, and transcriptome data with ground truth survival and histologic grade labels. In a 15-fold cross-validation, our results demonstrate that the proposed multimodal fusion paradigm improves prognostic determinations from ground truth grading and molecular subtyping, as well as unimodal deep networks trained on histology and genomic data alone. The proposed method establishes insight and theory on how to train deep networks on multimodal biomedical data in an intuitive manner, which will be useful for other problems in medicine that seek to combine heterogeneous data streams for understanding diseases and predicting response and resistance to treatment. Code and trained models are made available at: https://github.com/mahmoodlab/PathomicFusion.</p>
    </div>
    
    
    <div class="bibtex hidden">
      <pre>@article{chen2019pathomic,
  doi = {10.1109/tmi.2020.3021387},
  year = {2020},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Chen, Richard J. and Lu, Ming Y. and Wang, Jingwen and Williamson, Drew F. K. and Rodig, Scott J. and Lindeman, Neal I. and Mahmood, Faisal},
  title = {Pathomic Fusion: An Integrated Framework for Fusing Histopathology and Genomic Features for Cancer Diagnosis and Prognosis},
  journal = {{IEEE} Transactions on Medical Imaging},
  arxiv = {1912.08937},
  abbr = {chen2019pathomic.png},
  honor = {Top 5 Posters, NVIDIA GTC 2020},
  oral = {https://www.youtube.com/watch?v=TrjGEUVX5YE},
  code = {https://github.com/mahmoodlab/PathomicFusion},
  press = {https://blogs.nvidia.com/blog/2019/11/07/harvard-pathology-lab-data-fusion-ai-cancer/},
  selected = {true}
}
</pre>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3">
  
    <img class="img-fluid" src="/assets/pubimg/diao2021efficient.png">
  
  </div>

  <div id="diao2021efficient" class="col-sm-8">
    
      <div class="title">Efficient Cellular Annotation of Histopathology Slides with Real-Time AI augmentation</div>
      <div class="author">
        
          

          

          

          
            
              
                
                  James A. Diao*,
                
              
            
          
        
          

          

          

          
            
              
                <em>Richard J. Chen*</em>,
              
            
          
        
          

          

          

          
            
              
                
                  and Joseph C. Kvedar
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>npj Digital Medicine</em>
      
      
        2021
      
      
      </div>

      <div class="honor">
        
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1038/s41746-021-00534-0" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    
    
    
    
      <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In recent years, a steady swell of biological image data has driven rapid progress in healthcare applications of computer vision and machine learning. To make sense of this data, scientists often rely on detailed annotations from domain experts for training artificial intelligence (AI) algorithms. The time-consuming and costly process of collecting annotations presents a sizable bottleneck for AI research and development. HALS (Human-Augmenting Labeling System) is a collaborative human-AI labeling workflow that uses an iterative “review-and-revise” model to improve the efficiency of this critical process in computational pathology.</p>
    </div>
    
    
    <div class="bibtex hidden">
      <pre>@article{diao2021efficient,
  doi = {10.1038/s41746-021-00534-0},
  url = {https://doi.org/10.1038/s41746-021-00534-0},
  year = {2021},
  month = nov,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {4},
  number = {1},
  author = {Diao*, James A. and Chen*, Richard J. and Kvedar, Joseph C.},
  title = {Efficient Cellular Annotation of Histopathology Slides with Real-Time {AI} augmentation},
  journal = {npj Digital Medicine},
  abbr = {diao2021efficient.png},
  selected = {true}
}
</pre>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3">
  
    <img class="img-fluid" src="/assets/pubimg/chen2015variations.png">
  
  </div>

  <div id="chen2015variations" class="col-sm-8">
    
      <div class="title">Variations in Glycogen Synthesis in Human Pluripotent Stem Cells with Altered Pluripotent States</div>
      <div class="author">
        
          

          

          

          
            
              
                <em>Richard J. Chen</em>,
              
            
          
        
          

          

          

          
            
              
                
                  Guofeng Zhang,
                
              
            
          
        
          

          

          

          
            
              
                
                  Susan H. Garfield,
                
              
            
          
        
          

          

          

          
            
              
                
                  Yi-Jun Shi,
                
              
            
          
        
          

          

          

          
            
              
                
                  Kevin G. Chen,
                
              
            
          
        
          

          

          

          
            
              
                
                  Pamela G. Robey,
                
              
            
          
        
          

          

          

          
            
              
                
                  and Richard D. Leapman
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>PLOS ONE</em>
      
      
        2015
      
      
      </div>

      <div class="honor">
        
          2013 Intel STS Semifinalist
        
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1371/journal.pone.0142554" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    
    
    
    
      <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Human pluripotent stem cells (hPSCs) represent very promising resources for cell-based regenerative medicine. It is essential to determine the biological implications of some fundamental physiological processes (such as glycogen metabolism) in these stem cells. In this report, we employ electron, immunofluorescence microscopy, and biochemical methods to study glycogen synthesis in hPSCs. Our results indicate that there is a high level of glycogen synthesis (0.28 to 0.62 μg/μg proteins) in undifferentiated human embryonic stem cells (hESCs) compared with the glycogen levels (0 to 0.25 μg/μg proteins) reported in human cancer cell lines. Moreover, we found that glycogen synthesis was regulated by bone morphogenetic protein 4 (BMP-4) and the glycogen synthase kinase 3 (GSK-3) pathway. Our observation of glycogen bodies and sustained expression of the pluripotent factor Oct-4 mediated by the potent GSK-3 inhibitor CHIR-99021 reveals an altered pluripotent state in hPSC culture. We further confirmed glycogen variations under different naïve pluripotent cell growth conditions based on the addition of the GSK-3 inhibitor BIO. Our data suggest that primed hPSCs treated with naïve growth conditions acquire altered pluripotent states, similar to those naïve-like hPSCs, with increased glycogen synthesis. Furthermore, we found that suppression of phosphorylated glycogen synthase was an underlying mechanism responsible for altered glycogen synthesis. Thus, our novel findings regarding the dynamic changes in glycogen metabolism provide new markers to assess the energetic and various pluripotent states in hPSCs. The components of glycogen metabolic pathways offer new assays to delineate previously unrecognized properties of hPSCs under different growth conditions.</p>
    </div>
    
    
    <div class="bibtex hidden">
      <pre>@article{chen2015variations,
  doi = {10.1371/journal.pone.0142554},
  url = {https://doi.org/10.1371/journal.pone.0142554},
  year = {2015},
  month = nov,
  publisher = {Public Library of Science ({PLoS})},
  volume = {10},
  number = {11},
  pages = {e0142554},
  author = {Chen, Richard J. and Zhang, Guofeng and Garfield, Susan H. and Shi, Yi-Jun and Chen, Kevin G. and Robey, Pamela G. and Leapman, Richard D.},
  editor = {Lako, Majlinda},
  title = {Variations in Glycogen Synthesis in Human Pluripotent Stem Cells with Altered Pluripotent States},
  journal = {{PLOS} {ONE}},
  abbr = {chen2015variations.png},
  honor = {2013 Intel STS Semifinalist},
  selected = {true}
}
</pre>
    </div>
    
  </div>
</div></li></ol>
</div>

    

    
  </article>

</div>
    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Richard J. Chen.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
